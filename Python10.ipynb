{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg9hFWlA7QHU"
      },
      "source": [
        "# Lecture 10: TensorFlow Keras for Regression Neural Networks\n",
        "By the end of this lecture, you will be able to:\n",
        "1. Develop a shallow neural network using TensorFlow Keras in Python for a regression problem\n",
        "2. Develop a deep neural network using TensorFlow Keras in Python for a regression problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIHs0ZFMouaw"
      },
      "source": [
        "# 10.1. Multi-Layer Shallow and Deep Neural Networks for Regression\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> <img src=\t\"\thttps://i.ibb.co/FX66Gbw/11-1.png\t\"\twidth=\"500\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p23BFbW6jVVR",
        "cellView": "form"
      },
      "source": [
        "#@title Import, loading data, split data, and calibrate data all in one!\n",
        "# (copy-paste from Lecture08)\n",
        "import pandas                as pd\n",
        "import sklearn.preprocessing as prp # previously we names it pg!\n",
        "\n",
        "data_tr   = pd.read_csv('/content/sample_data/california_housing_train.csv')\n",
        "data_te   = pd.read_csv('/content/sample_data/california_housing_test.csv')\n",
        "\n",
        "datain_tr = data_tr.iloc[:,:-1]\n",
        "dataou_tr = data_tr.iloc[:,-1:]\n",
        "\n",
        "datain_te = data_te.iloc[:,:-1]\n",
        "dataou_te = data_te.iloc[:,-1:]\n",
        "\n",
        "fun_calibration_in = prp.MinMaxScaler(feature_range=(0,1))\n",
        "fun_calibration_in.fit(datain_tr)\n",
        "\n",
        "fun_calibration_ou = prp.MinMaxScaler(feature_range=(0,1))\n",
        "fun_calibration_ou.fit(dataou_tr)\n",
        "\n",
        "datain_tr_calibrated = fun_calibration_in.transform(datain_tr)\n",
        "datain_te_calibrated = fun_calibration_in.transform(datain_te)\n",
        "\n",
        "dataou_tr_calibrated = fun_calibration_ou.transform(dataou_tr)\n",
        "dataou_te_calibrated = fun_calibration_ou.transform(dataou_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVorbR67e7tR",
        "cellView": "form"
      },
      "source": [
        "#@title Import TensorFlow\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73stPL4Ze9HX",
        "cellView": "form"
      },
      "source": [
        "#@title Define neural network parameters\n",
        "in_neurons = datain_tr_calibrated.shape[1]\n",
        "ou_neurons = dataou_tr_calibrated.shape[1]\n",
        "\n",
        "hn_neurons = [100,50,25]\n",
        "\n",
        "ac_fun     = ['relu', 'relu', 'relu', 'linear']\n",
        "\n",
        "ls_fun     = 'mean_squared_error'\n",
        "op_val     = 'adam'\n",
        "it_val     = 100\n",
        "bt_size    = 16\n",
        "\n",
        "sh_val     = True # shuffle\n",
        "vr_val     = 1    # learning to be printed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLJndjejjYuh",
        "cellView": "form"
      },
      "source": [
        "#@title Construct the neural network\n",
        "\n",
        "net        = tf.keras.models.Sequential() # back-to-back layers of neurons (platform)\n",
        "\n",
        "net.add( tf.keras.layers.Dense(units=hn_neurons[0], activation=ac_fun[0], input_dim = in_neurons) ) # input layer and the 1st hidden layer\n",
        "net.add( tf.keras.layers.Dense(units=hn_neurons[1], activation=ac_fun[1]) )                         # 2nd hidden layer\n",
        "net.add( tf.keras.layers.Dense(units=hn_neurons[2], activation=ac_fun[2]) )                         # 3rd hidden layer\n",
        "net.add( tf.keras.layers.Dense(units=ou_neurons   , activation=ac_fun[3]) )                         # output layer\n",
        "\n",
        "net.compile(optimizer = op_val, loss = ls_fun) # compile the network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxglXCFvHXOf",
        "cellView": "form"
      },
      "source": [
        "#@title Network summary\n",
        "net.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1JKKASBHd_E",
        "cellView": "form"
      },
      "source": [
        "#@title Train the network\n",
        "history = net.fit(datain_tr_calibrated,\n",
        "                  dataou_tr_calibrated,\n",
        "                  epochs     = it_val ,\n",
        "                  batch_size = bt_size, \n",
        "                  verbose    = vr_val ,\n",
        "                  shuffle    = sh_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDuJKOM71i4Q",
        "cellView": "form"
      },
      "source": [
        "#@title Estimate outputs of testing data\n",
        "dataes_te_calibrated = net.predict(datain_te_calibrated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOnF3GeT3meC",
        "cellView": "form"
      },
      "source": [
        "#@title Plot testing real vs estimated values \n",
        "import matplotlib as mtl\n",
        "\n",
        "mtl.pyplot.figure(figsize=[5,5])\n",
        "\n",
        "mtl.pyplot.plot(dataou_te_calibrated, dataes_te_calibrated, 'b*',markersize = 1)\n",
        "mtl.pyplot.plot([-0.2,1.2], [-0.2,1.2],'r--',linewidth = 2)\n",
        "\n",
        "mtl.pyplot.xlabel('Real Testing Outputs | Calibrated', fontsize = 14)\n",
        "mtl.pyplot.ylabel('Estimated Testing Outputs | Calibrated', fontsize = 14)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRT8jEVZNgkG",
        "cellView": "form"
      },
      "source": [
        "#@title Plot iteration vs loss\n",
        "mtl.pyplot.figure(figsize=[5,5])\n",
        "mtl.pyplot.plot(history.history['loss'],'--')\n",
        "mtl.pyplot.title('Model Loss', fontsize = 20)\n",
        "mtl.pyplot.ylabel('Loss', fontsize = 20)\n",
        "mtl.pyplot.xlabel('Iteration Number', fontsize = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84pjuhOT5Ipy",
        "cellView": "form"
      },
      "source": [
        "#@title Online materials\n",
        "# Look into Keras documentations at www.keras.io\n",
        "# Look into sklearn library at www.scikit-learn.org"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISl4yRGv3WPF"
      },
      "source": [
        "# Lecture 10: TensorFlow Keras for Regression Neural Networks\n",
        "In this lecture, you learned about:\n",
        "1. How to develop a shallow neural network using TensorFlow Keras in Python for a regression problem\n",
        "2. How to develop a deep neural network using TensorFlow Keras in Python for a regression problem\n",
        "\n",
        "***In the next lecture, we will learn about TensorFlow Keras for Classification Neural Networks***\n"
      ]
    }
  ]
}